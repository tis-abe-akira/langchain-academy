{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
      "metadata": {
        "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e"
      },
      "source": [
        "# Chain\n",
        "\n",
        "## Review\n",
        "\n",
        "ノード、通常のエッジ、条件付きエッジを使用して、シンプルなグラフを構築しました。\n",
        "\n",
        "## Goals\n",
        "\n",
        "それでは、4つの[概念](https://python.langchain.com/v0.2/docs/concepts/)を組み合わせたシンプルなチェーンを構築してみましょう：\n",
        "\n",
        "* グラフの状態として[チャットメッセージ](https://python.langchain.com/v0.2/docs/concepts/#messages)を使用する\n",
        "* グラフのノード内で[チャットモデル](https://python.langchain.com/v0.2/docs/concepts/#chat-models)を使用する\n",
        "* チャットモデルに[ツールをバインド](https://python.langchain.com/v0.2/docs/concepts/#tools)する\n",
        "* グラフのノード内で[ツール呼び出しを実行](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)する\n",
        "\n",
        "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
      "metadata": {
        "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core langgraph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
      "metadata": {
        "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e"
      },
      "source": [
        "## Messages\n",
        "\n",
        "チャットモデルは[`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages)を使用でき、これは会話内のさまざまな役割を捉えます。\n",
        "\n",
        "LangChainはさまざまなメッセージタイプに対応しており、`HumanMessage`、`AIMessage`、`SystemMessage`、および`ToolMessage`が含まれます。\n",
        "\n",
        "これらは、ユーザーからのメッセージ、チャットモデルからのメッセージ、チャットモデルに対する動作指示、ツール呼び出しからのメッセージを表します。\n",
        "\n",
        "それでは、メッセージのリストを作成しましょう。\n",
        "\n",
        "各メッセージには、以下のような要素を指定できます：\n",
        "\n",
        "* `content` - メッセージの内容\n",
        "* `name` - オプションで、メッセージの作成者\n",
        "* `response_metadata` - オプションで、メタデータの辞書（例：通常`AIMessage`に対してモデルプロバイダによって設定される）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
      "metadata": {
        "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
        "outputId": "16bfef82-951f-402e-a4c4-2a271cf8170f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Model\n",
            "\n",
            "So you said you were researching ocean mammals?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Lance\n",
            "\n",
            "Yes, that's right.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Name: Model\n",
            "\n",
            "Great, what would you like to learn about.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "Name: Lance\n",
            "\n",
            "I want to learn about the best place to see Orcas in the US.\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
        "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
        "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
        "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
        "\n",
        "for m in messages:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
      "metadata": {
        "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e"
      },
      "source": [
        "## Chat Models\n",
        "\n",
        "[チャットモデル](https://python.langchain.com/v0.2/docs/concepts/#chat-models)は、メッセージのシーケンスを入力として使用でき、前述のメッセージタイプをサポートしています。\n",
        "\n",
        "選択肢は[たくさんあります](https://python.langchain.com/v0.2/docs/concepts/#chat-models)が、OpenAIを使ってみましょう。\n",
        "\n",
        "`OPENAI_API_KEY`が設定されているか確認し、設定されていない場合は入力を求められます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
      "metadata": {
        "id": "2652d5ec-7602-4220-bc6e-b90783ab287b"
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
      "metadata": {
        "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5"
      },
      "source": [
        "チャットモデルを読み込み、メッセージリストを使って呼び出すことができます。\n",
        "\n",
        "結果は、特定の`response_metadata`を含むAIMessageとして表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
      "metadata": {
        "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
        "outputId": "7e449f74-e705-4e17-9e02-a6c8e5ed7b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "result = llm.invoke(messages)\n",
        "type(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
      "metadata": {
        "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
        "outputId": "9b6eb247-2089-4d89-891b-eb15bf33bdf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Orcas, also known as killer whales, can be observed in several locations in the United States, but one of the best places to see them is the Pacific Northwest, particularly around the San Juan Islands in Washington State. \\n\\n### Key Locations:\\n\\n1. **San Juan Islands, Washington:**\\n   - **Best Time:** The peak season is from May to September, but they can be seen year-round.\\n   - **Why It's Great:** The nutrient-rich waters attract a variety of marine life, making it an ideal habitat for orcas. There are both resident and transient orca pods in the area.\\n\\n2. **Puget Sound, Washington:**\\n   - **Best Time:** Summer months, primarily from May to September.\\n   - **Why It's Great:** Puget Sound is home to the Southern Resident orcas, which are a unique and endangered population.\\n\\n3. **Monterey Bay, California:**\\n   - **Best Time:** Spring and fall are the best times to see transient orcas.\\n   - **Why It's Great:** The nutrient-rich waters of Monterey Bay attract a variety of marine life, including orcas, which come to prey on seals and sea lions.\\n\\n4. **Southeast Alaska:**\\n   - **Best Time:** Summer months, from May to September.\\n   - **Why It's Great:** The Inside Passage is a prime location for spotting orcas, along with humpback whales and other marine animals.\\n\\n### Tips for Whale Watching:\\n- **Tours:** Consider booking a whale-watching tour with a reputable company that follows responsible wildlife viewing guidelines.\\n- **Binoculars and Camera:** Bring binoculars for a closer look and a camera with a good zoom lens to capture the experience.\\n- **Weather:** Dress in layers and prepare for variable weather conditions, especially if you're going out on a boat.\\n\\n### Conservation Note:\\nOrcas face various threats, including habitat destruction, pollution, and reduced prey availability. Supporting conservation efforts and choosing eco-friendly tour operators can help protect these magnificent creatures for future generations.\\n\\nIs there anything more specific you’d like to know about orcas or whale watching?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 427, 'prompt_tokens': 67, 'total_tokens': 494}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5', 'finish_reason': 'stop', 'logprobs': None}, id='run-98914d63-e629-401b-a74e-dea0e68eff03-0', usage_metadata={'input_tokens': 67, 'output_tokens': 427, 'total_tokens': 494})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
      "metadata": {
        "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
        "outputId": "be45a8e8-17c0-4b1c-b195-6c8235099e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 427,\n",
              "  'prompt_tokens': 67,\n",
              "  'total_tokens': 494},\n",
              " 'model_name': 'gpt-4o-2024-05-13',\n",
              " 'system_fingerprint': 'fp_157b3831f5',\n",
              " 'finish_reason': 'stop',\n",
              " 'logprobs': None}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.response_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
      "metadata": {
        "id": "4718bd5c-5314-4405-a164-f1fe912ae306"
      },
      "source": [
        "## Tools\n",
        "\n",
        "ツールは、モデルが外部システムとやり取りしたい場合に便利です。\n",
        "\n",
        "外部システム（例：API）は、自然言語ではなく、特定の入力スキーマやペイロードを必要とすることが多くあります。\n",
        "\n",
        "たとえばAPIをツールとしてバインドすると、モデルにその必要な入力スキーマを認識させることができます。\n",
        "\n",
        "モデルは、ユーザーからの自然言語入力に基づいてツールを呼び出すことを選択します。\n",
        "\n",
        "そして、ツールのスキーマに準拠した出力を返します。\n",
        "\n",
        "[多くのLLMプロバイダーがツールの呼び出し](https://python.langchain.com/v0.1/docs/integrations/chat/)をサポートしており、LangChainでの[ツール呼び出しインターフェース](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/)はシンプルです。\n",
        "\n",
        "任意のPython `function`を`ChatModel.bind_tools(function)`に渡すだけで利用できます。\n",
        "\n",
        "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a942b1",
      "metadata": {
        "id": "17a942b1"
      },
      "source": [
        "ツール呼び出しの簡単な例を示しましょう！\n",
        "\n",
        "multiply関数が私たちのツールです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
      "metadata": {
        "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1"
      },
      "outputs": [],
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply a and b.\n",
        "\n",
        "    Args:\n",
        "        a: first int\n",
        "        b: second int\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "llm_with_tools = llm.bind_tools([multiply])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a3f9dba",
      "metadata": {
        "id": "8a3f9dba"
      },
      "source": [
        "入力を渡すと、たとえば `\"What is 2 multiplied by 3\"` の場合、ツール呼び出しが返されます。\n",
        "\n",
        "ツール呼び出しには、関数の入力スキーマに一致する特定の引数と、呼び出す関数の名前が含まれています。\n",
        "\n",
        "```\n",
        "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
      "metadata": {
        "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
        "outputId": "63c4cc40-9228-4b16-e746-98d20c151397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_OP4qwtGk4gTIaIySPFHkpbB2', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 62, 'total_tokens': 79}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-534c7657-e889-4a20-b00f-a7e9e1475d5f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_OP4qwtGk4gTIaIySPFHkpbB2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 17, 'total_tokens': 79})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])\n",
        "tool_call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
      "metadata": {
        "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
        "outputId": "f2002584-e885-4d6d-f0ce-2e211f277e02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'id': 'call_OP4qwtGk4gTIaIySPFHkpbB2',\n",
              "  'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'},\n",
              "  'type': 'function'}]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_call.additional_kwargs['tool_calls']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
      "metadata": {
        "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e"
      },
      "source": [
        "## Using messages as state\n",
        "\n",
        "これらの基盤が整ったので、グラフの状態に[`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages)を使用できるようになりました。\n",
        "\n",
        "状態`MessagesState`を、単一のキー`messages`を持つ`TypedDict`として定義しましょう。\n",
        "\n",
        "`messages`は、単に上で定義したメッセージのリスト（例：`HumanMessage`など）です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
      "metadata": {
        "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langchain_core.messages import AnyMessage\n",
        "\n",
        "class MessagesState(TypedDict):\n",
        "    messages: list[AnyMessage]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
      "metadata": {
        "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e"
      },
      "source": [
        "## Reducers\n",
        "\n",
        "さて、ちょっとした問題があります！\n",
        "\n",
        "私たちが話し合ったように、各ノードは状態キー`messages`の新しい値を返します。\n",
        "\n",
        "しかし、この新しい値は以前の`messages`の値を[上書きしてしまいます](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers)。\n",
        "\n",
        "グラフが実行されるとき、私たちは`messages`の状態キーにメッセージを**追加**したいのです。\n",
        "\n",
        "これに対処するために[リデューサ関数](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers)を使用できます。\n",
        "\n",
        "リデューサを使うことで、状態の更新方法を指定できます。\n",
        "\n",
        "リデューサ関数が指定されていない場合、キーの更新は*上書きされる*と想定されますが、以前に見たように。\n",
        "\n",
        "しかし、メッセージを追加するために、事前に構築された`add_messages`リデューサを使用できます。\n",
        "\n",
        "これにより、既存のメッセージリストに新しいメッセージが追加されることが保証されます。\n",
        "\n",
        "私たちは単に`messages`キーに`add_messages`リデューサ関数をメタデータとして注釈付けする必要があります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
      "metadata": {
        "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class MessagesState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3663e574-ba15-46be-a37c-48c8052d693b",
      "metadata": {
        "id": "3663e574-ba15-46be-a37c-48c8052d693b"
      },
      "source": [
        "メッセージのリストをグラフの状態に持つことは非常に一般的なので、LangGraphには事前に構築された[`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)があります！\n",
        "\n",
        "`MessagesState`は次のように定義されています：\n",
        "\n",
        "* 事前構築された単一の`messages`キーを持つ\n",
        "* これは`AnyMessage`オブジェクトのリストです\n",
        "* `add_messages`リデューサを使用します\n",
        "\n",
        "通常、`MessagesState`を使用する方が、上記のようにカスタム`TypedDict`を定義するよりも冗長でなくなります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
      "metadata": {
        "id": "9ab516ee-eab1-4856-8210-99f1fe499672"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState\n",
        "\n",
        "class MessagesState(MessagesState):\n",
        "    # Add any keys needed beyond messages, which is pre-built\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
      "metadata": {
        "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c"
      },
      "source": [
        "もう少し詳しく見ていきましょう。add_messages リデューサーが単独でどのように機能するかを説明します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
      "metadata": {
        "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
        "outputId": "58ab0ef6-7e71-4019-9fee-70c477f1c134"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[AIMessage(content='Hello! How can I assist you?', name='Model', id='cd566566-0f42-46a4-b374-fe4d4770ffa7'),\n",
              " HumanMessage(content=\"I'm looking for information on marine biology.\", name='Lance', id='9b6c4ddb-9de3-4089-8d22-077f53e7e915'),\n",
              " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', name='Model', id='74a549aa-8b8b-48d4-bdf1-12e98404e44e')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initial state\n",
        "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
        "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
        "                   ]\n",
        "\n",
        "# New message to add\n",
        "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
        "\n",
        "# Test\n",
        "add_messages(initial_messages , new_message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
      "metadata": {
        "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2"
      },
      "source": [
        "## Our graph\n",
        "\n",
        "さて、`MessagesState` をグラフと共に使用してみましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
      "metadata": {
        "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
        "outputId": "167a0854-dc5e-44cd-bfad-e384310c6b36"
      },
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Node\n",
        "def tool_calling_llm(state: MessagesState):\n",
        "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
        "\n",
        "# Build graph\n",
        "builder = StateGraph(MessagesState)\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "builder.add_edge(\"tool_calling_llm\", END)\n",
        "graph = builder.compile()\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
      "metadata": {
        "id": "e8909771-7786-47d6-a53d-6bbc3b365737"
      },
      "source": [
        "If we pass in `Hello!`, the LLM responds without any tool calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
      "metadata": {
        "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
        "outputId": "1d5650e4-2810-4806-a3af-599c506263b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi there! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
      "metadata": {
        "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba"
      },
      "source": [
        "LLM は、入力またはタスクがそのツールによって提供される機能を必要とする場合、そのツールを使用することを選択します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
      "metadata": {
        "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
        "outputId": "531d383a-fc25-42c9-8078-e0f83fb0621d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Multiply 2 and 3!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (call_Er4gChFoSGzU7lsuaGzfSGTQ)\n",
            " Call ID: call_Er4gChFoSGzU7lsuaGzfSGTQ\n",
            "  Args:\n",
            "    a: 2\n",
            "    b: 3\n"
          ]
        }
      ],
      "source": [
        "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3!\")})\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "311fbae3",
      "metadata": {
        "id": "311fbae3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}